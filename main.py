"""
Main entry point for Smart Data Cleaning System - Phase 1
Demonstrates bulletproof file handling capabilities.
"""

import sys
import logging
from pathlib import Path
from typing import Optional

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.file_utils import FileHandler, create_sample_processor
from src.config import ensure_directories
from src.exceptions import DataCleaningError


def setup_logging() -> None:
    """Set up logging for the application."""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / 'smart_data_cleaning.log'),
            logging.StreamHandler()
        ]
    )


def verify_setup() -> bool:
    """Verify that the system is properly set up."""
    try:
        # Ensure directories exist
        ensure_directories()
        
        # Test file handler initialization
        FileHandler()
        
        # Check required modules
        import pandas as pd
        import numpy as np
        import psutil
        import tqdm
        
        print("âœ… All dependencies available")
        print("âœ… Directory structure created")
        print("âœ… System ready")
        
        return True
        
    except ImportError as e:
        print(f"âŒ Missing dependency: {e}")
        print("Run: pip install -r requirements.txt")
        return False
    except Exception as e:
        print(f"âŒ Setup error: {e}")
        return False


def main():
    """Main function demonstrating file handling capabilities."""
    
    print("ğŸ¯ Smart Data Cleaning System - Phase 1")
    print("=" * 50)
    
    # Set up logging
    setup_logging()
    
    # Verify setup
    print("\nğŸ”§ Verifying system setup...")
    if not verify_setup():
        print("\nâŒ Setup verification failed. Please fix the issues above.")
        return
    
    # Initialize file handler
    try:
        file_handler = FileHandler()
        print("\nâœ… File handler initialized successfully")
    except Exception as e:
        print(f"\nâŒ Failed to initialize file handler: {e}")
        return
    
    # Interactive file selection
    while True:
        print("\n" + "=" * 50)
        print("ğŸ“‹ OPTIONS:")
        print("1. ğŸ“Š Analyze a file")
        print("2. ğŸ”„ Process file in chunks (demo)")
        print("3. ğŸ§ª Run system tests")
        print("4. â„¹ï¸  Show system info")
        print("5. ğŸšª Exit")
        
        choice = input("\nEnter your choice (1-5): ").strip()
        
        if choice == '1':
            analyze_file(file_handler)
        elif choice == '2':
            process_file_demo(file_handler)
        elif choice == '3':
            run_tests()
        elif choice == '4':
            show_system_info()
        elif choice == '5':
            print("\nğŸ‘‹ Thanks for using Smart Data Cleaning System!")
            print("Phase 1 complete - ready for Phase 2 development!")
            break
        else:
            print("âŒ Invalid choice. Please enter 1-5.")


def analyze_file(file_handler: FileHandler) -> None:
    """Analyze a file and display comprehensive information."""
    
    file_path = input("\nğŸ“ Enter file path: ").strip().strip('"\'')
    
    if not file_path:
        print("âŒ No file path provided.")
        return
    
    try:
        # Get file information
        print("\nğŸ“Š Analyzing file...")
        file_info = file_handler.get_file_info(file_path)
        
        # Display file information
        print(f"\nâœ… FILE ANALYSIS RESULTS:")
        print(f"  ğŸ“ Name: {file_info['name']}")
        print(f"  ğŸ“ Size: {file_info['size_mb']:.2f} MB ({file_info['size_bytes']:,} bytes)")
        print(f"  ğŸ“„ Format: {file_info['extension']}")
        
        if 'estimated_rows' in file_info and file_info['estimated_rows'] > 0:
            print(f"  ğŸ“Š Estimated rows: {file_info['estimated_rows']:,}")
        
        if 'sheets' in file_info and file_info['sheets']:
            print(f"  ğŸ“‹ Excel sheets: {', '.join(file_info['sheets'])}")
        
        # Try to read file preview
        print("\nğŸ” Reading file preview...")
        
        if file_info['size_mb'] > 100:
            print("  âš ï¸  Large file detected - using chunked reading")
            chunk_iterator = file_handler.read_file(file_path, use_chunks=True, chunk_size=1000)
            preview_df = next(iter(chunk_iterator))
            print(f"  ğŸ“ Showing first 1,000 rows of ~{file_info.get('estimated_rows', '?'):,} total rows")
        else:
            preview_df = file_handler.read_file(file_path, use_chunks=False)
            print(f"  ğŸ“ Loaded complete file: {len(preview_df):,} rows")
        
        # Display preview
        print(f"\nğŸ“ˆ DATA SUMMARY:")
        print(f"  ğŸ”¢ Shape: {preview_df.shape[0]:,} rows Ã— {preview_df.shape[1]} columns")
        print(f"  ğŸ“‹ Columns: {list(preview_df.columns)}")
        print(f"\nğŸ“Š Data types:")
        for col, dtype in preview_df.dtypes.items():
            print(f"    {col}: {dtype}")
        
        # Show basic statistics
        numeric_cols = preview_df.select_dtypes(include=['number']).columns
        if len(numeric_cols) > 0:
            print(f"\nğŸ“Š Numeric column statistics:")
            stats = preview_df[numeric_cols].describe()
            print(stats.to_string())
        
        print(f"\nğŸ” FIRST 5 ROWS:")
        print(preview_df.head().to_string(max_cols=10))
        
        # Memory usage and data quality
        memory_mb = preview_df.memory_usage(deep=True).sum() / (1024 ** 2)
        null_count = preview_df.isnull().sum().sum()
        
        print(f"\nğŸ’¾ MEMORY & QUALITY:")
        print(f"  ğŸ’¾ Memory usage: {memory_mb:.2f} MB")
        print(f"  â“ Null values: {null_count:,}")
        print(f"  ğŸ¯ Data completeness: {(1 - null_count/preview_df.size)*100:.1f}%")
        
    except DataCleaningError as e:
        print(f"âŒ Error: {e}")
        logging.error(f"File analysis error: {e}")
    except Exception as e:
        print(f"ğŸ’¥ Unexpected error: {e}")
        logging.error(f"Unexpected error in file analysis: {e}")


def process_file_demo(file_handler: FileHandler) -> None:
    """Demonstrate chunk processing capabilities."""
    
    file_path = input("\nğŸ“ Enter file path for chunk processing demo: ").strip().strip('"\'')
    
    if not file_path:
        print("âŒ No file path provided.")
        return
    
    try:
        print("\nğŸ”„ Processing file in chunks...")
        
        # Get file info first
        file_info = file_handler.get_file_info(file_path)
        print(f"ğŸ“Š File: {file_info['name']} ({file_info['size_mb']:.2f} MB)")
        
        # Create sample processor
        processor = create_sample_processor()
        
        # Process file
        chunk_size = 5000  # Process 5000 rows at a time
        print(f"ğŸ”„ Processing in chunks of {chunk_size:,} rows...")
        
        results = file_handler.process_large_file_in_chunks(
            file_path=file_path,
            processor_func=processor,
            chunk_size=chunk_size,
            show_progress=True
        )
        
        # Display results
        print(f"\nğŸ“Š CHUNK PROCESSING RESULTS:")
        print(f"  ğŸ“¦ Total chunks processed: {len(results)}")
        
        total_rows = sum(r['rows'] for r in results)
        total_memory = sum(r['memory_usage_mb'] for r in results)
        total_nulls = sum(r['null_values'] for r in results)
        
        print(f"  ğŸ“Š Total rows processed: {total_rows:,}")
        print(f"  ğŸ’¾ Total memory used: {total_memory:.2f} MB")
        print(f"  â“ Total null values found: {total_nulls:,}")
        print(f"  ğŸ“ˆ Average chunk size: {total_rows/len(results):.0f} rows")
        
        # Show chunk details
        if len(results) <= 10:
            print(f"\nğŸ“‹ DETAILED CHUNK BREAKDOWN:")
            for result in results:
                print(f"    Chunk {result['chunk_number']}: "
                      f"{result['rows']:,} rows, "
                      f"{result['memory_usage_mb']:.1f} MB, "
                      f"{result['null_values']:,} nulls")
        else:
            print(f"\nğŸ“‹ SAMPLE CHUNK DETAILS (first 5):")
            for result in results[:5]:
                print(f"    Chunk {result['chunk_number']}: "
                      f"{result['rows']:,} rows, "
                      f"{result['memory_usage_mb']:.1f} MB, "
                      f"{result['null_values']:,} nulls")
            print(f"    ... and {len(results)-5} more chunks")
        
    except DataCleaningError as e:
        print(f"âŒ Error: {e}")
        logging.error(f"Chunk processing error: {e}")
    except Exception as e:
        print(f"ğŸ’¥ Unexpected error: {e}")
        logging.error(f"Unexpected error in chunk processing: {e}")


def run_tests() -> None:
    """Run system tests."""
    print("\nğŸ§ª RUNNING SYSTEM TESTS...")
    print("=" * 30)
    
    try:
        import unittest
        
        # Discover and run tests
        loader = unittest.TestLoader()
        suite = loader.discover('tests', pattern='test_*.py')
        
        runner = unittest.TextTestRunner(verbosity=2)
        result = runner.run(suite)
        
        if result.wasSuccessful():
            print("\nâœ… All tests passed!")
        else:
            print(f"\nâŒ {len(result.failures)} test(s) failed, {len(result.errors)} error(s)")
            
    except ImportError:
        print("âŒ Tests not available - missing test files")
    except Exception as e:
        print(f"âŒ Test execution failed: {e}")


def show_system_info() -> None:
    """Show system information and capabilities."""
    print("\nğŸ–¥ï¸  SYSTEM INFORMATION:")
    print("=" * 30)
    
    try:
        import pandas as pd
        import numpy as np
        import psutil
        
        # System info
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('.')
        
        print(f"ğŸ“Š System Resources:")
        print(f"  ğŸ’¾ Memory: {memory.total / (1024**3):.1f} GB total, "
              f"{memory.available / (1024**3):.1f} GB available "
              f"({memory.percent:.1f}% used)")
        print(f"  ğŸ’½ Disk: {disk.total / (1024**3):.1f} GB total, "
              f"{disk.free / (1024**3):.1f} GB free "
              f"({(disk.used/disk.total)*100:.1f}% used)")
        
        # Library versions
        print(f"\nğŸ“š Library Versions:")
        print(f"  ğŸ¼ Pandas: {pd.__version__}")
        print(f"  ğŸ”¢ NumPy: {np.__version__}")
        print(f"  ğŸ“Š PSUtil: {psutil.__version__}")
        
        # Capabilities
        from src.config import SUPPORTED_FORMATS, MAX_FILE_SIZE, CHUNK_SIZE
        
        print(f"\nğŸ¯ System Capabilities:")
        print(f"  ğŸ“„ Supported formats: {', '.join(SUPPORTED_FORMATS)}")
        print(f"  ğŸ“ Max file size: {MAX_FILE_SIZE / (1024**3):.1f} GB")
        print(f"  ğŸ“¦ Default chunk size: {CHUNK_SIZE:,} rows")
        print(f"  ğŸ§  Memory threshold: {psutil.virtual_memory().percent:.1f}%")
        
        # Directory structure
        from src.config import BASE_DIR, INPUT_DIR, OUTPUT_DIR, TEMP_DIR, LOGS_DIR
        
        print(f"\nğŸ“ Directory Structure:")
        dirs = [
            ("Base", BASE_DIR),
            ("Input", INPUT_DIR), 
            ("Output", OUTPUT_DIR),
            ("Temp", TEMP_DIR),
            ("Logs", LOGS_DIR)
        ]
        
        for name, path in dirs:
            exists = "âœ…" if path.exists() else "âŒ"
            print(f"  {exists} {name}: {path}")
        
    except Exception as e:
        print(f"âŒ Error getting system info: {e}")


if __name__ == "__main__":
    main()